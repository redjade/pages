<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>읽기 | redjade pages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="읽기" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Meta Pseudo Labels 훑기" />
<meta property="og:description" content="Meta Pseudo Labels 훑기" />
<link rel="canonical" href="https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html" />
<meta property="og:url" content="https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html" />
<meta property="og:site_name" content="redjade pages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-30T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-03-30T00:00:00-05:00","dateModified":"2020-03-30T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html"},"description":"Meta Pseudo Labels 훑기","@type":"BlogPosting","url":"https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html","headline":"읽기","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/pages/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://redjade.github.io/pages/feed.xml" title="redjade pages" />


<!--<link rel="shortcut icon" type="image/x-icon" href="/pages/images/favicon.ico">-->
<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>읽기 | redjade pages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="읽기" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Meta Pseudo Labels 훑기" />
<meta property="og:description" content="Meta Pseudo Labels 훑기" />
<link rel="canonical" href="https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html" />
<meta property="og:url" content="https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html" />
<meta property="og:site_name" content="redjade pages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-30T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-03-30T00:00:00-05:00","dateModified":"2020-03-30T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html"},"description":"Meta Pseudo Labels 훑기","@type":"BlogPosting","url":"https://redjade.github.io/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html","headline":"읽기","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://redjade.github.io/pages/feed.xml" title="redjade pages" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/pages/">redjade pages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/pages/about/">About</a><a class="page-link" href="/pages/search/">Search</a><a class="page-link" href="/pages/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">&lt;Meta Pseudo Label&gt; 읽기</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-30T00:00:00-05:00" itemprop="datePublished">
        Mar 30, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/pages/categories/#Meta Pseudo Label">Meta Pseudo Label</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#meta-pseudo-labels-훑기">Meta Pseudo Labels 훑기</a></li>
<li class="toc-entry toc-h1"><a href="#들어가기">들어가기</a></li>
<li class="toc-entry toc-h1"><a href="#동기">동기</a>
<ul>
<li class="toc-entry toc-h2"><a href="#label-smoothing">Label smoothing</a></li>
<li class="toc-entry toc-h2"><a href="#temperature-tuning">Temperature tuning</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#참고">참고</a></li>
<li class="toc-entry toc-h1"><a href="#용어">용어</a>
<ul>
<li class="toc-entry toc-h2"><a href="#label-smoothing-1">Label Smoothing</a></li>
<li class="toc-entry toc-h2"><a href="#준지도학습에서-pseudo-label">준지도학습에서 pseudo label</a></li>
<li class="toc-entry toc-h2"><a href="#pseudo-label">Pseudo Label</a></li>
</ul>
</li>
</ul><h1 id="meta-pseudo-labels-훑기">
<a class="anchor" href="#meta-pseudo-labels-%ED%9B%91%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>Meta Pseudo Labels 훑기</h1>

<ul>
  <li>심층신경망 학습은 네트웍의 예측과 타겟 분포 사이의 cross entropy를 최소화하는 것으로 해석할 수 있음.</li>
  <li>지도학습에서 타겟 분포는 보통 실제 one-hot 벡터.</li>
  <li>준지도학습(semi-supervised learning)에서는 보통 사전학습한 teacher model이 타겟 분포를 생성하고, 메인 네트웍을 학습함.</li>
  <li>이 논문은 메인 네트웍의 학습 상태를 기반으로 타겟 분포 조정을 학습하면 더 나은 성능에 이르게 됨을 보임.
    <ul>
      <li>메타-학습 알고리즘을 제안하는데, teacher가 메인 네트웍의 학습을 개선하는 방향으로 학습 데이터의 타겟 분포를 조정함.</li>
      <li>따로 떼놓은 검증 데이터(held-out validation data)로 계산한 policy gradient로 teacher를 학습함.</li>
    </ul>
  </li>
  <li>실험은 CIFAR-10, SVHN, ImageNet 에서 state-of-the-art.</li>
</ul>

<h1 id="들어가기">
<a class="anchor" href="#%EB%93%A4%EC%96%B4%EA%B0%80%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>들어가기</h1>

<ul>
  <li>cross entropy loss : KL divergence from a target distribution over all the possible classes to the distribution predicted by a network
    <ul>
      <li>여기서 자연스레 이어지는 질문: 이 타겟 분포는 무엇이어야 하지?</li>
      <li>지도학습의 경우, one-hot, smoothed version of one-hot(label smoothing<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> <sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup>)</li>
      <li>준지도학습의 경우, pseudo label라고도 부르는 타겟 분포를 사용하는데,</li>
      <li>label 있는 데이터로 학습한 날카로워지고 무뎌진(약해진) teacher 모델을 이용해서</li>
      <li>label 없는 데이터를 처리한 분포를 타겟 분포로 사용한다.<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup> <sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup>
</li>
      <li>이 두 경우 모두 학습 전의 _사전 정보(prior)_로 디자인한 경험지식(heuristic)이라서, 학습되는 신경망의 학습 상태에 맞춰서 조정할 수 없다는 약점이 내재해 있다.</li>
    </ul>
  </li>
  <li>그래서 타겟 분포를 메타-학습할 수 있는 방법을 제안함.
    <ul>
      <li>teacher model 디자인 : 메인 모델(앞으로 student 모델이라고 부르겠음)을 학습할 때 사용할 input data에 대해서 분포를 할당함.</li>
      <li>student model 학습 : student model을 검증 데이터셋으로 진행한 성능 평가를 근거로 해서, 다음번에 검증 데이터셋으로 더 나은 성능을 보일 만한 타겟 분포를 teacher가 생성함.</li>
      <li>이 방법이 pseudo label 기법과 유사해서 _Meta Pseudo Label_이라고 이름붙임.</li>
      <li>MPL을 사용하면, student의 학습 상태에 따라서 타겟 분포를 조정할 수 있어서, pseudo label과 지도 학습을 사용한 분류기보다 더 나은 성능을 보여준다.</li>
    </ul>
  </li>
</ul>

<h1 id="동기">
<a class="anchor" href="#%EB%8F%99%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>동기</h1>
<ul>
  <li>세팅
    <ul>
      <li>C개의 클래스가 있고 $\Theta$로 파라미터화된 모델</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>보통 타겟 분포 $q_* ( Y</td>
              <td>X )$와 모델 분포 $p_\Theta ( Y</td>
              <td>X )$ 사이의 크로스 엔트로피를 최소화함</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>완전 지도 학습에서는, 타겟 분포는 one-hot 벡터로 정의된다.</li>
  <li>knowledge distillation에서는 잘 학습된 더 큰 모델의 “dark knowledge”를 작은 모델로 압축한다. 더 큰 모델의 분포를 타겟 분포로 사용한다.</li>
  <li>준지도 학습에서는, 제한된 label 데이터로 학습한 $q_\xi$ 모델로 unlabl 데이터의 클래스를 예측한 분포를 사용한다. 두 가지 버전이 있다. 그런데 이 둘은 일반적으로 잘 작동하지만 종종 최적의 선택이 아니라는 최근 연구가 있다.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>Hard label : $q_* ( Y</td>
      <td>x ) \overset{\Delta}{=} one-hot(argmax_y q_\xi ( y</td>
      <td>x ))$</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>Soft label : $q_* ( Y</td>
      <td>x ) \overset{\Delta}{=} q_\xi ( Y</td>
      <td>x )$</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>타겟 분포를 약간 조정하는 휴리스틱 두 가지가 있다: label smoothing과 temperature tuning.</li>
</ul>

<h2 id="label-smoothing">
<a class="anchor" href="#label-smoothing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Label smoothing</h2>

<h2 id="temperature-tuning">
<a class="anchor" href="#temperature-tuning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Temperature tuning</h2>

<h1 id="참고">
<a class="anchor" href="#%EC%B0%B8%EA%B3%A0" aria-hidden="true"><span class="octicon octicon-link"></span></a>참고</h1>

<ul>
  <li><a href="https://arxiv.org/abs/2003.10580">Meta Pseudo Labels</a></li>
</ul>

<h1 id="용어">
<a class="anchor" href="#%EC%9A%A9%EC%96%B4" aria-hidden="true"><span class="octicon octicon-link"></span></a>용어</h1>
<h2 id="label-smoothing-1">
<a class="anchor" href="#label-smoothing-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Label Smoothing</h2>
<h2 id="준지도학습에서-pseudo-label">
<a class="anchor" href="#%EC%A4%80%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5%EC%97%90%EC%84%9C-pseudo-label" aria-hidden="true"><span class="octicon octicon-link"></span></a>준지도학습에서 pseudo label</h2>
<h2 id="pseudo-label">
<a class="anchor" href="#pseudo-label" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pseudo Label</h2>

<p><a href="http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf">Pseudo-Label</a> 방법은, 사전학습된 모델로 label 없는 데이터를 처리한 예측 확률의 최대값을 해당 데이터의 타겟 클래스로 삼는 방법이다. 사전학습된 모델을 이용해서, label 데이터와 unlabel 데이터를 <em>동시에</em> 학습한다. unlabel 데이터의 loss function은 지도학습의 loss와 동일한 형태를 가지되 regularizer 스타일로 loss function에 더하며 hyperparameter로 강도를 조절한다.</p>

<p><em>cluster assumption</em><sup id="fnref:5"><a href="#fn:5" class="footnote">5</a></sup>에 따르면, 일반화를 위해서 결정 경계(decision boundary)는 저밀도 구간에 있어야 한다. 한편, <em>entropy regularization</em><sup id="fnref:6"><a href="#fn:6" class="footnote">6</a></sup>에 따르면 레이블 없는 데이터가 보여주는 클래스 확률 분포의 조건부 엔트로피를 최소화할 때 클래스 사이의 밀도 분포를 낮게 만들어준다. 즉, 클래스 사이의 분포를 덜 겹치게하기 위해서 unlabel 데이터의 엔트로피를 최소화하는 것이다. Pseudo Label 논문은 pseudo label로 추가한 loss가 entropy regularization의 형태와 동일함을 보인다.</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://arxiv.org/abs/1906.02629">When Does Label Smoothing Help?</a> <a href="#fnref:1" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:2">
      <p><a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a> <a href="#fnref:2" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://arxiv.org/abs/1904.12848">Unsupervised Data Augmentation for Consistency Training</a> <a href="#fnref:3" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:4">
      <p><a href="https://arxiv.org/abs/1905.02249">MixMatch: A Holistic Approach to Semi-Supervised Learning</a> <a href="#fnref:4" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:5">
      <p>Chapelle, O., and Zien, A.  Semi-supervised classication by low density separation. AISTATS, 2005, (pp.5764). <a href="#fnref:5" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:6">
      <p>Yves  Grandvalet  and  Yoshua  Bengio,   Entropy  Regularization,    In: Semi-Supervised  Learning,  pages 151–168, MIT Press, 2006. <a href="#fnref:6" class="reversefootnote">↩</a></p>
    </li>
  </ol>
</div>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="redjade/pages"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/pages/meta%20pseudo%20label/2020/03/30/meta-pseudo-label.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/pages/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/pages/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/pages/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Pages by redjade.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/redjade" title="redjade"><svg class="svg-icon grey"><use xlink:href="/pages/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
